#!/usr/bin/env node
/**
 * Create Jira Epic "AI Content & Video Engine for Retail" with 10 Stories and 4 Subtasks per Story.
 * Ensures components AI, ERP, CRM, Monetization exist; links all Stories to Epic.
 *
 * Usage: node scripts/jira-create-ai-content-epic.mjs [--dry-run]
 * Env: JIRA_URL, JIRA_USERNAME, JIRA_API_TOKEN (.env.jira / .env).
 */

import fs from "fs";
import path from "path";

const PROJECT_KEY = "GAQNO";
const DEFAULT_JIRA_URL = "https://gaqno.atlassian.net";
const EPIC_LINK_FIELD = "customfield_10014";
const REQUIRED_COMPONENTS = ["AI", "ERP", "CRM", "Monetization"];
const SUBTASK_SUMMARIES = [
  "Backend implementation",
  "Frontend implementation",
  "AI / Prompt logic",
  "Validation / Tests",
];

const EPIC_SUMMARY = "AI Content & Video Engine for Retail";
const EPIC_DESCRIPTION = `- Vision: Enable retailers to generate AI-powered marketing content even with minimal CRM/ERP maturity.
- Strategy: Start with discovery, define minimum product data contracts, then progressively integrate.
- Monetization: GMV-based SaaS pricing.
- Success Metrics:
  - GMV attributed to AI content
  - Time to publish first content
  - Adoption rate per tenant
- Risks:
  - Incomplete product data
  - ERP/CRM fragmentation
  - AI hallucination due to poor inputs`;

const STORIES = [
  {
    summary: "Product Data Discovery (SPIKE)",
    description: `As a platform, we need to understand what minimum product data is available across CRM, ERP, and PDV to enable AI content generation.

*Acceptance Criteria:*
- Inventory current product fields in CRM, ERP, and PDV
- Identify gaps for AI usage
- Define MVP product data contract`,
  },
  {
    summary: "Define Product Data Contract (MVP)",
    description: `As a system, we want a standardized product data contract so AI can consume consistent inputs.

*Acceptance Criteria:*
- Define required vs optional fields
- Versioned schema documented
- Validation rules defined`,
  },
  {
    summary: "ERP Product Foundation",
    description: `As a retailer, I want ERP to expose the minimum product data required for AI content generation.

*Acceptance Criteria:*
- Product name, price, category available
- Product images accessible
- API endpoint exposed`,
  },
  {
    summary: "CRM Enrichment Foundation",
    description: `As a platform, we want CRM to enrich product data with customer and persona insights.

*Acceptance Criteria:*
- Basic customer segments available
- Buyer persona mapping defined
- CRM data linked to product ID`,
  },
  {
    summary: "AI Product Semantic Profile",
    description: `As a system, we want to build a semantic profile from incomplete data using fallback strategies.

*Acceptance Criteria:*
- Graceful handling of missing fields
- AI inference for missing attributes
- Confidence score per profile`,
  },
  {
    summary: "AI Text Content Generation (MVP)",
    description: `As a retailer, I want AI-generated marketing text even if my catalog is incomplete.

*Acceptance Criteria:*
- Generate copy from partial data
- Highlight assumptions to user
- Manual review supported`,
  },
  {
    summary: "AI Video Generation (Experimental MVP)",
    description: `As a retailer, I want basic AI-generated videos using templates and static assets.

*Acceptance Criteria:*
- Template-based videos
- No avatar dependency
- Preview before publish`,
  },
  {
    summary: "Omnichannel Distribution",
    description: `As a retailer, I want content distributed even without deep CRM automation.

*Acceptance Criteria:*
- WhatsApp as primary channel
- Manual publish option
- Delivery confirmation`,
  },
  {
    summary: "GMV Attribution & Tracking",
    description: `As a platform, we want to attribute GMV even with partial data.

*Acceptance Criteria:*
- Campaign-based tracking
- PDV as source of truth
- Attribution confidence score`,
  },
  {
    summary: "GMV-Based Billing",
    description: `As a SaaS platform, we want to monetize based on GMV generated by AI content.

*Acceptance Criteria:*
- GMV aggregation
- Fee calculation
- Billing visibility`,
  },
];

function loadEnvFile(filename) {
  const envPath = path.join(process.cwd(), filename);
  if (!fs.existsSync(envPath)) return;
  for (const line of fs.readFileSync(envPath, "utf8").split("\n")) {
    const m = line.match(/^\s*([A-Za-z_][A-Za-z0-9_]*)\s*=\s*(.+)\s*$/);
    if (m)
      process.env[m[1]] = m[2]
        .trim()
        .replace(/^["']|["',]+$/g, "")
        .trim();
  }
}

function loadJiraEnv() {
  loadEnvFile(".env.jira");
  loadEnvFile(".env");
  const baseUrl = (process.env.JIRA_URL || DEFAULT_JIRA_URL)
    .trim()
    .replace(/\/$/, "");
  const username = process.env.JIRA_USERNAME;
  const apiToken = process.env.JIRA_API_TOKEN;
  if (!username || !apiToken) {
    throw new Error(
      "Set JIRA_USERNAME and JIRA_API_TOKEN (or .env.jira / .env)"
    );
  }
  const auth = Buffer.from(`${username}:${apiToken}`).toString("base64");
  return { baseUrl, auth };
}

function descriptionToAdf(plainText) {
  if (!plainText || !String(plainText).trim()) return undefined;
  const paragraphs = String(plainText)
    .trim()
    .split(/\n+/)
    .map((s) => s.trim())
    .filter(Boolean);
  if (!paragraphs.length) return undefined;
  return {
    type: "doc",
    version: 1,
    content: paragraphs.map((text) => ({
      type: "paragraph",
      content: [{ type: "text", text }],
    })),
  };
}

async function jira(env, pathname, opts = {}) {
  const res = await fetch(`${env.baseUrl}${pathname}`, {
    ...opts,
    headers: {
      Accept: "application/json",
      "Content-Type": "application/json",
      Authorization: `Basic ${env.auth}`,
      ...opts.headers,
    },
  });
  const text = await res.text();
  if (!res.ok) throw new Error(`${res.status} ${pathname}: ${text}`);
  return text ? JSON.parse(text) : null;
}

async function getProjectIssueTypes(env) {
  const project = await jira(
    env,
    `/rest/api/3/project/${PROJECT_KEY}?expand=issueTypes`
  );
  const types = project.issueTypes || [];
  const epic = types.find(
    (t) => !t.subtask && ["Epic", "Épico"].includes(t.name)
  );
  const story =
    types.find((t) => !t.subtask && ["Story", "História"].includes(t.name)) ||
    types.find(
      (t) => !t.subtask && t.name && /story|história|historia/i.test(t.name)
    );
  const subtask = types.find((t) => t.subtask === true);
  if (!epic || !story || !subtask) {
    throw new Error(
      `Project ${PROJECT_KEY} missing issue types: Epic=${!!epic}, Story=${!!story}, Subtask=${!!subtask}`
    );
  }
  return { epicId: epic.id, storyId: story.id, subtaskId: subtask.id };
}

async function getExistingComponents(env) {
  const list = await jira(env, `/rest/api/3/project/${PROJECT_KEY}/components`);
  return Array.isArray(list) ? list : [];
}

async function createComponent(env, name, dryRun) {
  if (dryRun) return { name, id: null };
  const res = await fetch(`${env.baseUrl}/rest/api/3/component`, {
    method: "POST",
    headers: {
      Accept: "application/json",
      "Content-Type": "application/json",
      Authorization: `Basic ${env.auth}`,
    },
    body: JSON.stringify({
      name,
      project: PROJECT_KEY,
    }),
  });
  if (res.status === 201) {
    const data = await res.json();
    return { name: data.name, id: data.id };
  }
  const err = await res.text();
  throw new Error(`Create component ${name}: ${res.status} ${err}`);
}

async function ensureComponents(env, dryRun) {
  let existing = await getExistingComponents(env);
  const byName = new Map(existing.map((c) => [c.name, c]));
  for (const name of REQUIRED_COMPONENTS) {
    if (!byName.has(name)) {
      const created = await createComponent(env, name, dryRun);
      if (created.id) byName.set(name, created);
      else byName.set(name, { name });
    }
  }
  if (!dryRun) existing = await getExistingComponents(env);
  return REQUIRED_COMPONENTS.map(
    (name) =>
      byName.get(name) || existing.find((c) => c.name === name) || { name }
  ).filter((c) => c && (c.id || c.name));
}

async function createEpic(env, typeIds, componentList, dryRun) {
  const componentRefs = componentList
    .filter((c) => c.id)
    .map((c) => ({ id: c.id }));
  const body = {
    fields: {
      project: { key: PROJECT_KEY },
      issuetype: { id: String(typeIds.epicId) },
      summary: EPIC_SUMMARY,
      labels: ["ai", "retail", "saas", "gmv", "discovery"],
      priority: { name: "Medium" },
      ...(descriptionToAdf(EPIC_DESCRIPTION) && {
        description: descriptionToAdf(EPIC_DESCRIPTION),
      }),
      ...(componentRefs.length > 0 && { components: componentRefs }),
    },
  };
  if (dryRun) {
    console.log("[dry-run] Would create Epic:", EPIC_SUMMARY);
    return { key: "GAQNO-DRY-EPIC" };
  }
  const created = await jira(env, "/rest/api/3/issue", {
    method: "POST",
    body: JSON.stringify(body),
  });
  return created;
}

async function createStory(env, typeIds, story, dryRun) {
  const body = {
    fields: {
      project: { key: PROJECT_KEY },
      issuetype: { id: String(typeIds.storyId) },
      summary: story.summary,
      priority: { name: "Medium" },
      ...(descriptionToAdf(story.description) && {
        description: descriptionToAdf(story.description),
      }),
    },
  };
  if (dryRun) {
    console.log("[dry-run] Would create Story:", story.summary);
    return {
      key: `GAQNO-DRY-${story.summary.slice(0, 10).replace(/\s/g, "")}`,
    };
  }
  const created = await jira(env, "/rest/api/3/issue", {
    method: "POST",
    body: JSON.stringify(body),
  });
  return created;
}

async function setEpicLink(env, issueKey, epicKey, dryRun) {
  if (dryRun) return;
  await jira(env, `/rest/api/3/issue/${issueKey}`, {
    method: "PUT",
    body: JSON.stringify({
      fields: { [EPIC_LINK_FIELD]: epicKey },
    }),
  });
}

async function createSubtask(env, typeIds, parentKey, summary, dryRun) {
  if (dryRun) {
    console.log(`  [dry-run] Subtask under ${parentKey}: ${summary}`);
    return { key: `${parentKey}-subtask` };
  }
  const created = await jira(env, "/rest/api/3/issue", {
    method: "POST",
    body: JSON.stringify({
      fields: {
        project: { key: PROJECT_KEY },
        parent: { key: parentKey },
        issuetype: { id: String(typeIds.subtaskId) },
        summary,
        priority: { name: "Medium" },
      },
    }),
  });
  return created;
}

async function main() {
  const dryRun = process.argv.includes("--dry-run");
  const env = loadJiraEnv();
  if (dryRun) console.log("DRY RUN – no changes will be made.\n");

  console.log("1. Ensuring components:", REQUIRED_COMPONENTS.join(", "));
  const componentList = await ensureComponents(env, dryRun);

  console.log("2. Resolving issue type IDs...");
  const typeIds = await getProjectIssueTypes(env);

  console.log("3. Creating Epic...");
  const epic = await createEpic(env, typeIds, componentList, dryRun);
  console.log("   Epic:", epic.key);

  console.log("4. Creating Stories...");
  const storyKeys = [];
  for (const story of STORIES) {
    const created = await createStory(env, typeIds, story, dryRun);
    storyKeys.push(created.key);
    console.log("   ", created.key, story.summary);
  }

  if (!dryRun) {
    console.log("5. Linking Stories to Epic...");
    for (const key of storyKeys) {
      if (key.startsWith("GAQNO-"))
        await setEpicLink(env, key, epic.key, false);
    }
  } else {
    console.log("5. [dry-run] Would link all Stories to Epic");
  }

  console.log("6. Creating Subtasks (4 per Story)...");
  let subtaskCount = 0;
  for (const storyKey of storyKeys) {
    if (storyKey.startsWith("GAQNO-DRY")) continue;
    for (const summary of SUBTASK_SUMMARIES) {
      const created = await createSubtask(
        env,
        typeIds,
        storyKey,
        summary,
        dryRun
      );
      if (!dryRun) subtaskCount++;
    }
  }
  console.log("   Total subtasks:", dryRun ? "40 (dry-run)" : subtaskCount);

  console.log("\nDone.");
  console.log("Epic:", epic.key);
  console.log("Stories:", storyKeys.join(", "));
}

main().catch((e) => {
  console.error(e);
  process.exit(1);
});
